{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Prophesee Dataset Toolbox could not be found!\n",
      "         Only Prophesee DVS demo will not run properly.\n",
      "         Please install it from https://github.com/prophesee-ai/prophesee-automotive-dataset-toolbox\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from lava.lib.dl import slayer\n",
    "from obd1.dataset import evCIVIL\n",
    "from obd1.boundingbox import metrics,utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _yolo(x: torch.tensor,\n",
    "          anchors: torch.tensor,\n",
    "          clamp_max: float = 5.0) -> torch.tensor:\n",
    "    # converts raw predictions to bounding box predictions.\n",
    "    _, _, H, W, _, _ = x.shape\n",
    "    range_y, range_x = torch.meshgrid(\n",
    "        torch.arange(H, dtype=x.dtype, device=x.device),\n",
    "        torch.arange(W, dtype=x.dtype, device=x.device),\n",
    "        indexing='ij',\n",
    "    )\n",
    "    anchor_x, anchor_y = anchors[:, 0], anchors[:, 1]\n",
    "\n",
    "    x_center = (torch.sigmoid(x[:, :, :, :, 0:1, :])\n",
    "                + range_x[None, None, :, :, None, None]) / W\n",
    "    y_center = (torch.sigmoid(x[:, :, :, :, 1:2, :])\n",
    "                + range_y[None, None, :, :, None, None]) / H\n",
    "    width = (torch.exp(\n",
    "        x[:, :, :, :, 2:3, :].clamp(\n",
    "            max=clamp_max)) * anchor_x[None, :, None, None, None, None]) / W\n",
    "    height = (torch.exp(\n",
    "        x[:, :, :, :, 3:4, :].clamp(\n",
    "            max=clamp_max)) * anchor_y[None, :, None, None, None, None]) / H\n",
    "    confidence = torch.sigmoid(x[:, :, :, :, 4:5, :])\n",
    "    classes = torch.softmax(x[:, :, :, :, 5:, :], dim=-2)\n",
    "    #classes = torch.sigmoid(x[:, :, :, :, 5:, :])\n",
    "\n",
    "    x = torch.concat([x_center, y_center, width, height,\n",
    "                      confidence, classes], dim=-2)\n",
    "\n",
    "    if torch.isnan(x).any() or torch.isinf(x).any():\n",
    "        print(f'{torch.isnan(x_center).any()=}')\n",
    "        print(f'{torch.isinf(x_center).any()=}')\n",
    "        print(f'{torch.isnan(y_center).any()=}')\n",
    "        print(f'{torch.isinf(y_center).any()=}')\n",
    "        print(f'{torch.isnan(width).any()=}')\n",
    "        print(f'{torch.isinf(width).any()=}')\n",
    "        print(f'{torch.isnan(height).any()=}')\n",
    "        print(f'{torch.isinf(height).any()=}')\n",
    "        raise RuntimeError('Ecountered NaN and Inf!')\n",
    "\n",
    "    return x  # batch, anchor, height, width, predictions, time \n",
    "\n",
    "\n",
    "\n",
    "def yolo(x: torch.tensor, anchors: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"Evaluates YOLO bounding box prediction from raw network output.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.tensor\n",
    "            Raw prediciton tensor.\n",
    "        anchors : torch.tensor\n",
    "            Anchors associated with the prediction head.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor\n",
    "            Output bounding boxes.\n",
    "        \"\"\"\n",
    "        clamp_max = 5.0\n",
    "        N, _, _, _, P, T = x.shape\n",
    "        return _yolo(x, anchors, clamp_max).reshape([N, -1, P, T])\n",
    "\n",
    "def yolo_raw(x: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"Transforms raw YOLO prediction to eventual output order i.e.\n",
    "        NCHWT order to (batch, num_anchors, num_outputs, height, width, time).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.tensor\n",
    "            Raw prediction output of the network.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor\n",
    "            Transformed raw prediction output for a head.\n",
    "        \"\"\"\n",
    "        num_anchors = 3\n",
    "\n",
    "        N, _, H, W, T = x.shape\n",
    "        return x.reshape(N,num_anchors,-1, H, W, T).permute(0, 1, 3, 4, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_detection_scores(fmap_file,ann_file,num_box_stat_file):\n",
    "\n",
    "    pred_fmaps = np.load(fmap_file)\n",
    "    all_anns = np.load(ann_file)\n",
    "    num_boxes_per_sample_arr = np.load(num_box_stat_file)\n",
    "    num_boxes_per_sample_arr = num_boxes_per_sample_arr.reshape(-1,1)\n",
    "    print(\"num boxes per sample arr \",num_boxes_per_sample_arr)\n",
    "\n",
    "    data_path = \"/home/atiye/latest_dataset/\"\n",
    "    test_csv_file = \"test_files_event_based.txt\"\n",
    "    param_dict = {\"TSteps\" : 7, \"tbins\" : 1 ,\"quantized_h\" : 260 ,\"quantized_w\" : 346}\n",
    "        \n",
    "    valid_TSteps = 7\n",
    "    stats = slayer.utils.LearningStats(accuracy_str='AP@0.5')\n",
    "    ap_stats = metrics.APstats(iou_threshold=0.5)\n",
    "    anchors = torch.tensor([[0.2800, 0.2200],\n",
    "        [0.3800, 0.4800],\n",
    "        [0.9000, 0.7800]])\n",
    "    anchors = anchors.unsqueeze(0)\n",
    "    conf_thres = 0.1\n",
    "\n",
    "    track_id = 0\n",
    "    total_process_boxes = 0\n",
    "\n",
    "    for i,(num_boxes,pred_fmap) in enumerate(zip(num_boxes_per_sample_arr,pred_fmaps)):\n",
    "\n",
    "        num_boxes = num_boxes[0]\n",
    "        bboxes = all_anns[track_id:(track_id + num_boxes),:]\n",
    "        print(\"bboxes \",bboxes)\n",
    "        print(\"bboxes shape \",bboxes.shape)\n",
    "        print(\"pred_fmap shape \",pred_fmap.shape)\n",
    "        total_process_boxes += bboxes.shape[0]\n",
    "\n",
    "        track_id += num_boxes\n",
    "\n",
    "        bboxes = torch.from_numpy(bboxes)\n",
    "\n",
    "        pred_fmap = torch.from_numpy(pred_fmap)\n",
    "        pred_fmap = pred_fmap.unsqueeze(0) #add batch dim at the begining\n",
    "        pred_fmap = pred_fmap.unsqueeze(-1) #add time dimension\n",
    "        #now batch,C,H,W,T dimension\n",
    "        predictions = yolo_raw(pred_fmap)\n",
    "        predictions = [predictions]\n",
    "        \n",
    "        predictions = [prediction/(valid_TSteps + 0.0) for prediction in predictions]\n",
    "        T = 1 #inputs.shape[-1]  #This means prediction should be done at the last time step\n",
    "        try:\n",
    "            predictions = torch.concat([yolo(p, a) for (p, a)\n",
    "                        in zip(predictions, anchors)],dim=1)\n",
    "        except RuntimeError:\n",
    "            print('Runtime error on MAP predictions calculation.'\n",
    "                            'continuing')\n",
    "            continue\n",
    "        predictions = [utils.nms(predictions[..., t],conf_threshold = conf_thres)\n",
    "                            for t in range(T)]\n",
    "            \n",
    "        for t in range(T):\n",
    "                ap_stats.update(predictions[t],[bboxes]) #bboxes is torch array, predictions[t] is a list. in that list torch.tensor of (75,6) (5x5x3,6)\n",
    "        \n",
    "        stats.testing.num_samples += 1\n",
    "        stats.testing.correct_samples = ap_stats[:] * stats.testing.num_samples\n",
    "\n",
    "    print(\"stats.testing.accuracy \",stats.testing.accuracy)\n",
    "    stats.update()\n",
    "    print(\"total process boxes \",total_process_boxes)\n",
    "    print(\"all_anns.shape[0] \",all_anns.shape[0])\n",
    "    assert total_process_boxes == all_anns.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num boxes per sample arr  [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "bboxes  [[0.6965409  0.31967375 0.16214623 0.2712264  1.         0.        ]]\n",
      "bboxes shape  (1, 6)\n",
      "pred_fmap shape  (21, 5, 5)\n",
      "bboxes  [[0.5692807 0.4086085 0.1572327 0.2702437 1.        0.       ]]\n",
      "bboxes shape  (1, 6)\n",
      "pred_fmap shape  (21, 5, 5)\n",
      "bboxes  [[0.3830582  0.5162146  0.14838837 0.20833333 1.         0.        ]]\n",
      "bboxes shape  (1, 6)\n",
      "pred_fmap shape  (21, 5, 5)\n",
      "bboxes  [[0.3614387 0.5393082 0.1582154 0.2250393 1.        0.       ]]\n",
      "bboxes shape  (1, 6)\n",
      "pred_fmap shape  (21, 5, 5)\n",
      "bboxes  [[0.30001965 0.5663325  0.18671383 0.21619497 1.         0.        ]]\n",
      "bboxes shape  (1, 6)\n",
      "pred_fmap shape  (21, 5, 5)\n",
      "bboxes  [[0.2184552  0.5741942  0.18278302 0.18671383 1.         0.        ]]\n",
      "bboxes shape  (1, 6)\n",
      "pred_fmap shape  (21, 5, 5)\n",
      "stats.testing.accuracy  0.015\n",
      "total process boxes  6\n",
      "all_anns.shape[0]  6\n"
     ]
    }
   ],
   "source": [
    "#feature core\n",
    "fmap_file = \"float_fmaps.npy\"\n",
    "ann_file = \"float_anns.npy\"\n",
    "num_box_stat_file = \"float_num_boxes.npy\"\n",
    "\n",
    "calculate_detection_scores(fmap_file,ann_file,num_box_stat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize annotations together with fmaps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lava_dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
